# -*- coding: utf-8 -*-
"""ObjectRecognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oPOYtsdIQkjYkAJEvr5TKGNaGVvH5qQI
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c cifar-10

!ls

from zipfile import ZipFile
dataset='/content/cifar-10.zip'
with ZipFile(dataset,'r') as zip:
  zip.extractall()
  print("The dataset is extracted")

!ls

!pip install py7zr

import py7zr
archive=py7zr.SevenZipFile('/content/train.7z',mode='r')
archive.extractall()
archive.close()

!ls

"""Dependencies getting imported"""

import os
import numpy as np
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split

filenames=os.listdir('/content/train')

type(filenames)

len(filenames)

print(filenames[0:5])
print(filenames[-5:])

"""Label Processing"""

labels_df=pd.read_csv('/content/trainLabels.csv')

labels_df.shape

labels_df.head()

labels_df[labels_df['id']==15332]

labels_df['label'].value_counts()

labels_dict={'airplane':0,'automobile':1,'bird':2,'cat':3,'deer':4,'dog':5,'frog':6,'horse':7,'ship':8,'truck':9}
labels=[labels_dict[i] for i in labels_df['label']]

print(labels[0:5])
print(labels[-5:])

import cv2
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/train/3066.png')
cv2_imshow(img)

import cv2
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/train/15332.png')
cv2_imshow(img)

labels_df[labels_df['id']==3066]

id_list=list(labels_df['id'])

print(id_list[0:5])
print(id_list[-5:])

"""Image Processing"""

train_data_folder='/content/train/'
data=[]
for id in id_list:
  image=Image.open(train_data_folder+str(id)+'.png')
  image=np.array(image)
  data.append(image)

type(data)

X=np.array(data)
Y=np.array(labels)

print(X.shape)
print(Y.shape)

"""Train Test Split"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=2,test_size=.2)

X_train_scaled=X_train/255
X_test_scaled=X_test/255

X_train_scaled

X_train[0]



"""Building Neural Network"""

import tensorflow as tf
from tensorflow import keras

num_of_classes=10
model=keras.Sequential([
    keras.layers.Flatten(input_shape=(32,32,3)),
    keras.layers.Dense(64,activation='relu'),
    keras.layers.Dense(num_of_classes,activation='softmax')
])

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',
              metrics=['acc'])

model.fit(X_train_scaled,Y_train,validation_split=.1,epochs=10)

"""RESNET 50"""

from tensorflow.keras import Sequential,models,layers
from tensorflow.keras.layers import Dense,Dropout,Flatten,BatchNormalization
from tensorflow.keras.models import load_model,Model
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras import optimizers

convolutional_base=ResNet50(weights='imagenet',include_top=False,input_shape=(256,256,3))
convolutional_base.summary()

num_of_classes=10
model=models.Sequential()
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(convolutional_base)
model.add(layers.Flatten())
model.add(layers.BatchNormalization())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(num_of_classes, activation='softmax'))

model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5),loss='sparse_categorical_crossentropy',metrics=['acc'])

history=model.fit(X_train_scaled,Y_train,validation_split=.1,epochs=10)

loss,accuracy=model.evaluate(X_test_scaled,Y_test)
print('Test Accuracy=',accuracy)

h=history
plt.plot(h.history['loss'],label='train loss')
plt.plot(h.history['val_loss'], label='validation loss')
plt.legend()
plt.show()

# plot the accuracy value
plt.plot(h.history['acc'], label='train accuracy')
plt.plot(h.history['val_acc'], label='validation accuracy')
plt.legend()
plt.show()